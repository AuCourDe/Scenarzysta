"""
ModuÅ‚ eksperymentalnej korelacji dokumentÃ³w.

Ten moduÅ‚ sÅ‚uÅ¼y do analizy wielu dokumentÃ³w i wykrywania ich wzajemnych relacji.
ObsÅ‚uguje scenariusze gdzie:
1. Jeden dokument to przepis (scenariusze), drugi to dane testowe
2. Dokumenty opisujÄ… powiÄ…zane procesy/funkcjonalnoÅ›ci
3. Dokumenty siÄ™ uzupeÅ‚niajÄ… (np. specyfikacja + instrukcja uÅ¼ytkownika)

ALGORYTM:
1. Dla kaÅ¼dego dokumentu generuje podsumowanie (co zawiera, jaki typ danych)
2. Generuje przykÅ‚adowe scenariusze z prÃ³bkÄ… danych
3. Analizuje korelacje miÄ™dzy dokumentami
4. OkreÅ›la typ relacji i czÄ™stotliwoÅ›Ä‡ wykorzystania
"""
import json
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum


class DocumentType(Enum):
    """Typ dokumentu wykryty przez analizÄ™."""
    SPECIFICATION = "specification"  # Specyfikacja techniczna
    TEST_DATA = "test_data"  # Dane testowe
    USER_MANUAL = "user_manual"  # Instrukcja uÅ¼ytkownika
    PROCESS_DESCRIPTION = "process_description"  # Opis procesu
    REQUIREMENTS = "requirements"  # Wymagania
    UNKNOWN = "unknown"


class CorrelationType(Enum):
    """Typ korelacji miÄ™dzy dokumentami."""
    DATA_SOURCE = "data_source"  # Jeden dokument to ÅºrÃ³dÅ‚o danych dla drugiego
    COMPLEMENTARY = "complementary"  # Dokumenty siÄ™ uzupeÅ‚niajÄ…
    DEPENDENT_PROCESS = "dependent_process"  # Procesy zaleÅ¼ne od siebie
    SPECIFICATION_IMPLEMENTATION = "spec_impl"  # Specyfikacja + implementacja
    NONE = "none"  # Brak korelacji


@dataclass
class DocumentSummary:
    """Podsumowanie dokumentu."""
    filename: str
    doc_type: DocumentType
    summary: str
    key_elements: List[str]  # GÅ‚Ã³wne elementy (funkcje, dane, procesy)
    sample_scenarios: List[str]  # PrzykÅ‚adowe scenariusze
    data_samples: List[str]  # PrÃ³bki danych (jeÅ›li zawiera dane testowe)
    estimated_coverage: int  # Szacowana liczba scenariuszy


@dataclass
class DocumentCorrelation:
    """Korelacja miÄ™dzy dwoma dokumentami."""
    doc1_filename: str
    doc2_filename: str
    correlation_type: CorrelationType
    correlation_strength: float  # 0.0 - 1.0
    description: str
    usage_pattern: str  # Jak wykorzystaÄ‡ oba dokumenty razem
    example_scenario: str  # PrzykÅ‚adowy scenariusz wykorzystujÄ…cy oba dokumenty


class DocumentCorrelator:
    """Eksperymentalny korelator dokumentÃ³w."""
    
    def __init__(self, ollama_url: str = "http://localhost:11434", ollama_model: str = "gemma2:2b"):
        self.ollama_url = ollama_url
        self.ollama_model = ollama_model
        self.summaries: Dict[str, DocumentSummary] = {}
        self.correlations: List[DocumentCorrelation] = []
    
    def _call_ollama(self, prompt: str, system_prompt: str = None, max_retries: int = 3) -> str:
        """WywoÅ‚uje API Ollama."""
        for attempt in range(max_retries):
            try:
                payload = {
                    "model": self.ollama_model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 4096
                    }
                }
                
                if system_prompt:
                    payload["system"] = system_prompt
                
                response = requests.post(
                    f"{self.ollama_url}/api/generate",
                    json=payload,
                    timeout=300
                )
                
                if response.status_code == 200:
                    return response.json().get('response', '')
                
            except Exception as e:
                print(f"  BÅ‚Ä…d wywoÅ‚ania Ollama (prÃ³ba {attempt + 1}): {e}")
                if attempt == max_retries - 1:
                    raise
        
        return ""
    
    def analyze_document(self, content: str, filename: str) -> DocumentSummary:
        """
        Analizuje pojedynczy dokument i tworzy jego podsumowanie.
        
        Args:
            content: TreÅ›Ä‡ dokumentu
            filename: Nazwa pliku
            
        Returns:
            DocumentSummary z analizÄ… dokumentu
        """
        print(f"  AnalizujÄ™ dokument: {filename}")
        
        # Ogranicz treÅ›Ä‡ do analizy
        content_sample = content[:15000] if len(content) > 15000 else content
        
        prompt = f"""Przeanalizuj poniÅ¼szy dokument i okreÅ›l:

1. TYP DOKUMENTU (jeden z: specification, test_data, user_manual, process_description, requirements, unknown)
2. KRÃ“TKIE PODSUMOWANIE (2-3 zdania) - co zawiera dokument
3. GÅÃ“WNE ELEMENTY - lista 5-10 kluczowych elementÃ³w (funkcje, dane, procesy)
4. PRZYKÅADOWE SCENARIUSZE - 3-5 potencjalnych scenariuszy testowych
5. PRÃ“BKI DANYCH - jeÅ›li dokument zawiera dane testowe, podaj 3-5 przykÅ‚adÃ³w
6. SZACOWANA LICZBA SCENARIUSZY - ile scenariuszy moÅ¼na wygenerowaÄ‡ z tego dokumentu

ZwrÃ³Ä‡ TYLKO JSON w formacie:
{{
  "doc_type": "specification",
  "summary": "Dokument opisuje...",
  "key_elements": ["element1", "element2"],
  "sample_scenarios": ["Scenariusz 1", "Scenariusz 2"],
  "data_samples": ["Dane 1", "Dane 2"],
  "estimated_coverage": 50
}}

DOKUMENT ({filename}):
{content_sample}
"""
        
        response = self._call_ollama(prompt)
        
        try:
            # WyciÄ…gnij JSON z odpowiedzi
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                data = json.loads(response[json_start:json_end])
            else:
                raise ValueError("Nie znaleziono JSON w odpowiedzi")
            
            doc_type = DocumentType(data.get('doc_type', 'unknown'))
            
            summary = DocumentSummary(
                filename=filename,
                doc_type=doc_type,
                summary=data.get('summary', ''),
                key_elements=data.get('key_elements', []),
                sample_scenarios=data.get('sample_scenarios', []),
                data_samples=data.get('data_samples', []),
                estimated_coverage=data.get('estimated_coverage', 0)
            )
            
            self.summaries[filename] = summary
            return summary
            
        except Exception as e:
            print(f"  BÅ‚Ä…d parsowania analizy dokumentu: {e}")
            return DocumentSummary(
                filename=filename,
                doc_type=DocumentType.UNKNOWN,
                summary="Nie udaÅ‚o siÄ™ przeanalizowaÄ‡ dokumentu",
                key_elements=[],
                sample_scenarios=[],
                data_samples=[],
                estimated_coverage=0
            )
    
    def analyze_correlation(self, doc1: DocumentSummary, doc2: DocumentSummary, 
                           content1: str, content2: str) -> DocumentCorrelation:
        """
        Analizuje korelacjÄ™ miÄ™dzy dwoma dokumentami.
        
        Args:
            doc1, doc2: Podsumowania dokumentÃ³w
            content1, content2: TreÅ›ci dokumentÃ³w (skrÃ³cone)
            
        Returns:
            DocumentCorrelation z opisem relacji
        """
        print(f"  AnalizujÄ™ korelacjÄ™: {doc1.filename} <-> {doc2.filename}")
        
        # SkrÃ³Ä‡ treÅ›ci do analizy
        content1_sample = content1[:8000] if len(content1) > 8000 else content1
        content2_sample = content2[:8000] if len(content2) > 8000 else content2
        
        prompt = f"""Przeanalizuj dwa dokumenty i okreÅ›l ich wzajemnÄ… relacjÄ™.

DOKUMENT 1: {doc1.filename}
Typ: {doc1.doc_type.value}
Podsumowanie: {doc1.summary}
GÅ‚Ã³wne elementy: {', '.join(doc1.key_elements[:5])}
Fragment:
{content1_sample[:3000]}

DOKUMENT 2: {doc2.filename}
Typ: {doc2.doc_type.value}
Podsumowanie: {doc2.summary}
GÅ‚Ã³wne elementy: {', '.join(doc2.key_elements[:5])}
Fragment:
{content2_sample[:3000]}

OkreÅ›l:
1. TYP KORELACJI (jeden z: data_source, complementary, dependent_process, spec_impl, none)
   - data_source: jeden dokument to ÅºrÃ³dÅ‚o danych dla scenariuszy z drugiego
   - complementary: dokumenty siÄ™ uzupeÅ‚niajÄ… (np. rÃ³Å¼ne aspekty tego samego systemu)
   - dependent_process: procesy opisane w dokumentach sÄ… od siebie zaleÅ¼ne
   - spec_impl: jeden to specyfikacja, drugi to implementacja/instrukcja
   - none: brak istotnej korelacji

2. SIÅA KORELACJI (0.0 - 1.0)
   - 0.0-0.3: sÅ‚aba korelacja
   - 0.4-0.6: Å›rednia korelacja
   - 0.7-1.0: silna korelacja

3. OPIS RELACJI - jak dokumenty siÄ™ do siebie odnoszÄ…

4. WZORZEC UÅ»YCIA - jak wykorzystaÄ‡ oba dokumenty razem do generowania scenariuszy

5. PRZYKÅADOWY SCENARIUSZ - jeden przykÅ‚ad scenariusza wykorzystujÄ…cego oba dokumenty

ZwrÃ³Ä‡ TYLKO JSON:
{{
  "correlation_type": "data_source",
  "correlation_strength": 0.8,
  "description": "Dokument 1 zawiera dane testowe, ktÃ³re mogÄ… byÄ‡ uÅ¼yte w scenariuszach z dokumentu 2",
  "usage_pattern": "Dla kaÅ¼dego scenariusza z dokumentu 2, uÅ¼yj danych z odpowiedniej sekcji dokumentu 1",
  "example_scenario": "Scenariusz: Test logowania z danymi z tabeli uÅ¼ytkownikÃ³w (dok. 1) wedÅ‚ug procedury z instrukcji (dok. 2)"
}}
"""
        
        response = self._call_ollama(prompt)
        
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                data = json.loads(response[json_start:json_end])
            else:
                raise ValueError("Nie znaleziono JSON")
            
            correlation = DocumentCorrelation(
                doc1_filename=doc1.filename,
                doc2_filename=doc2.filename,
                correlation_type=CorrelationType(data.get('correlation_type', 'none')),
                correlation_strength=float(data.get('correlation_strength', 0.0)),
                description=data.get('description', ''),
                usage_pattern=data.get('usage_pattern', ''),
                example_scenario=data.get('example_scenario', '')
            )
            
            self.correlations.append(correlation)
            return correlation
            
        except Exception as e:
            print(f"  BÅ‚Ä…d parsowania korelacji: {e}")
            return DocumentCorrelation(
                doc1_filename=doc1.filename,
                doc2_filename=doc2.filename,
                correlation_type=CorrelationType.NONE,
                correlation_strength=0.0,
                description="Nie udaÅ‚o siÄ™ przeanalizowaÄ‡ korelacji",
                usage_pattern="",
                example_scenario=""
            )
    
    def generate_correlated_scenarios(self, documents: Dict[str, str]) -> Dict:
        """
        GÅ‚Ã³wna funkcja - analizuje wszystkie dokumenty i generuje strategiÄ™ korelacji.
        
        Args:
            documents: SÅ‚ownik {nazwa_pliku: treÅ›Ä‡}
            
        Returns:
            SÅ‚ownik z wynikami analizy i rekomendacjami
        """
        print(f"\n=== KORELACJA DOKUMENTÃ“W ({len(documents)} plikÃ³w) ===\n")
        
        # Krok 1: Analiza kaÅ¼dego dokumentu
        print("KROK 1: Analiza poszczegÃ³lnych dokumentÃ³w")
        for filename, content in documents.items():
            self.analyze_document(content, filename)
        
        # Krok 2: Analiza korelacji miÄ™dzy parami dokumentÃ³w
        print("\nKROK 2: Analiza korelacji miÄ™dzy dokumentami")
        filenames = list(documents.keys())
        for i in range(len(filenames)):
            for j in range(i + 1, len(filenames)):
                doc1 = self.summaries[filenames[i]]
                doc2 = self.summaries[filenames[j]]
                self.analyze_correlation(
                    doc1, doc2,
                    documents[filenames[i]],
                    documents[filenames[j]]
                )
        
        # Krok 3: OkreÅ›l strategiÄ™ generowania scenariuszy
        print("\nKROK 3: OkreÅ›lanie strategii")
        strategy = self._determine_strategy()
        
        # Przygotuj wynik
        result = {
            'documents': [
                {
                    'filename': s.filename,
                    'type': s.doc_type.value,
                    'summary': s.summary,
                    'key_elements': s.key_elements,
                    'sample_scenarios': s.sample_scenarios,
                    'estimated_coverage': s.estimated_coverage
                }
                for s in self.summaries.values()
            ],
            'correlations': [
                {
                    'doc1': c.doc1_filename,
                    'doc2': c.doc2_filename,
                    'type': c.correlation_type.value,
                    'strength': c.correlation_strength,
                    'description': c.description,
                    'usage_pattern': c.usage_pattern,
                    'example': c.example_scenario
                }
                for c in self.correlations
            ],
            'strategy': strategy
        }
        
        return result
    
    def _determine_strategy(self) -> Dict:
        """OkreÅ›la strategiÄ™ generowania scenariuszy na podstawie korelacji."""
        
        # ZnajdÅº najsilniejsze korelacje
        strong_correlations = [c for c in self.correlations if c.correlation_strength >= 0.6]
        
        if not strong_correlations:
            return {
                'type': 'independent',
                'description': 'Dokumenty nie wykazujÄ… silnych korelacji. Przetwarzaj kaÅ¼dy osobno.',
                'recommended_order': list(self.summaries.keys()),
                'data_flow': None
            }
        
        # SprawdÅº czy jest relacja data_source
        data_sources = [c for c in strong_correlations if c.correlation_type == CorrelationType.DATA_SOURCE]
        
        if data_sources:
            # ZnajdÅº dokument z danymi i dokument z procedurami
            strongest = max(data_sources, key=lambda x: x.correlation_strength)
            
            return {
                'type': 'data_driven',
                'description': f'Wykryto relacjÄ™ ÅºrÃ³dÅ‚a danych. {strongest.description}',
                'data_document': strongest.doc1_filename,
                'procedure_document': strongest.doc2_filename,
                'usage_pattern': strongest.usage_pattern,
                'example': strongest.example_scenario,
                'recommended_approach': (
                    'Iteruj przez dane z dokumentu ÅºrÃ³dÅ‚owego. '
                    'Dla kaÅ¼dego zestawu danych generuj scenariusz wedÅ‚ug procedury z drugiego dokumentu. '
                    'Pozwala to na wielokrotne wykorzystanie tego samego wzorca scenariusza z rÃ³Å¼nymi danymi.'
                )
            }
        
        # SprawdÅº czy sÄ… procesy zaleÅ¼ne
        dependent = [c for c in strong_correlations if c.correlation_type == CorrelationType.DEPENDENT_PROCESS]
        
        if dependent:
            strongest = max(dependent, key=lambda x: x.correlation_strength)
            
            return {
                'type': 'sequential',
                'description': f'Wykryto procesy zaleÅ¼ne. {strongest.description}',
                'process_order': [strongest.doc1_filename, strongest.doc2_filename],
                'usage_pattern': strongest.usage_pattern,
                'recommended_approach': (
                    'Generuj scenariusze w kolejnoÅ›ci procesÃ³w. '
                    'Wyniki scenariuszy z pierwszego procesu sÄ… warunkami wstÄ™pnymi dla drugiego. '
                    'UwzglÄ™dnij scenariusze integracyjne Å‚Ä…czÄ…ce oba procesy.'
                )
            }
        
        # DomyÅ›lnie - dokumenty uzupeÅ‚niajÄ…ce siÄ™
        strongest = max(strong_correlations, key=lambda x: x.correlation_strength)
        
        return {
            'type': 'complementary',
            'description': f'Dokumenty siÄ™ uzupeÅ‚niajÄ…. {strongest.description}',
            'usage_pattern': strongest.usage_pattern,
            'recommended_approach': (
                'Traktuj dokumenty jako rÃ³Å¼ne perspektywy tego samego systemu. '
                'Generuj scenariusze z kaÅ¼dego dokumentu, ale sprawdzaj spÃ³jnoÅ›Ä‡ miÄ™dzy nimi. '
                'UwzglÄ™dnij scenariusze integracyjne wykorzystujÄ…ce informacje z obu ÅºrÃ³deÅ‚.'
            )
        }
    
    def get_correlation_report(self) -> str:
        """Generuje czytelny raport z analizy korelacji."""
        report = []
        report.append("=" * 60)
        report.append("RAPORT KORELACJI DOKUMENTÃ“W")
        report.append("=" * 60)
        report.append("")
        
        # Podsumowania dokumentÃ³w
        report.append("PRZEANALIZOWANE DOKUMENTY:")
        report.append("-" * 40)
        for summary in self.summaries.values():
            report.append(f"\nðŸ“„ {summary.filename}")
            report.append(f"   Typ: {summary.doc_type.value}")
            report.append(f"   {summary.summary}")
            report.append(f"   Szacowane scenariusze: {summary.estimated_coverage}")
        
        # Korelacje
        report.append("\n\nKORELACJE:")
        report.append("-" * 40)
        for corr in self.correlations:
            strength_bar = "â–ˆ" * int(corr.correlation_strength * 10) + "â–‘" * (10 - int(corr.correlation_strength * 10))
            report.append(f"\nðŸ”— {corr.doc1_filename} <-> {corr.doc2_filename}")
            report.append(f"   Typ: {corr.correlation_type.value}")
            report.append(f"   SiÅ‚a: [{strength_bar}] {corr.correlation_strength:.1f}")
            report.append(f"   {corr.description}")
        
        report.append("\n" + "=" * 60)
        
        return "\n".join(report)


def correlate_documents(documents: Dict[str, str], ollama_url: str = "http://localhost:11434", 
                       ollama_model: str = "gemma2:2b") -> Dict:
    """
    Funkcja pomocnicza do korelacji dokumentÃ³w.
    
    Args:
        documents: SÅ‚ownik {nazwa_pliku: treÅ›Ä‡}
        ollama_url: URL Ollama
        ollama_model: Model Ollama
        
    Returns:
        Wyniki analizy korelacji
    """
    correlator = DocumentCorrelator(ollama_url, ollama_model)
    return correlator.generate_correlated_scenarios(documents)
